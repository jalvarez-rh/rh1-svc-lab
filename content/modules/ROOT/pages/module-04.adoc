[[data-ai]]

= Data & AI

[[sovereign-ai-overview]]

== Sovereign AI: Bringing Intelligence to Your Data

**AI Sovereignty** represents a critical evolution in how organizations approach artificial intelligence and machine learning. In an era where data privacy regulations are tightening, geopolitical tensions are reshaping technology supply chains, and organizations face increasing pressure to maintain control over their intellectual property, sovereign AI enables enterprises to build, train, and deploy AI models within their own controlled infrastructure—ensuring data never leaves your jurisdiction, models remain under your governance, and compliance requirements are met from the ground up.

Traditional AI approaches often require sending sensitive data to external cloud providers, relying on third-party model training services, or depending on proprietary platforms that limit your ability to customize and control your AI infrastructure. This creates significant risks: data sovereignty violations, regulatory non-compliance, intellectual property exposure, and vendor lock-in that can limit your strategic flexibility.

Red Hat OpenShift AI addresses these challenges by enabling you to run AI workloads on-premises or in your own cloud environments, bringing compute power directly to where your data resides. This approach ensures that:

* **Data Residency**: Your training data, models, and inference workloads remain within your geographic boundaries and infrastructure
* **Regulatory Compliance**: You maintain full control over data handling, meeting GDPR, HIPAA, and other regional compliance requirements
* **Intellectual Property Protection**: Your proprietary models and data remain under your direct control, reducing exposure to external parties
* **Operational Autonomy**: You can operate independently of external AI service providers, adapting to changing business and regulatory needs
* **Cost Optimization**: By bringing AI compute to your data, you reduce data transfer costs and avoid vendor lock-in pricing models

In this module, you will install Red Hat OpenShift AI and configure a DataScienceCluster that enables data scientists and developers to work with Jupyter notebooks, build machine learning pipelines, and deploy AI models—all while maintaining complete sovereignty over your data and infrastructure.

[[openshift-ai-installation]]

== Installing Red Hat OpenShift AI

Before data scientists can begin working with OpenShift, we need to install it. 

[[install-openshift-ai-operator]]

=== Install OpenShift AI Operator

The first script installs the Red Hat OpenShift AI Operator, which provides the foundational platform for running AI workloads on OpenShift.

*Procedure*

[source,sh,role=execute]
----
cd ~/rh1-svc-lab/ai-setup && ./setup.sh
----

[start=3]
. Verify the installation completed successfully. You should see output indicating:

+
[source,sh]
----
[SETUP] 
[SETUP] Retrieving OpenShift AI access information...
[SETUP] 
[SETUP] =========================================================
[SETUP] OpenShift AI Access Information
[SETUP] =========================================================
[SETUP] Dashboard URL: https://rhods-dashboard-redhat-ods-applications.apps.cluster-gk5g4.dynamic.redhatworkshops.io
[SETUP] Username: admin
[SETUP] Password: OpenShift admin password
[SETUP] =========================================================
[SETUP] 
----

[start=4]
. At the end of the script output, note the access information that will be displayed. This includes:
* Dashboard URL (will be available after DataScienceCluster is created)
* Username: admin
* Password: {openshift_cluster_admin_password}

Make sure you have access to the OpenShift AI dashboard before proceeding.

[[verify-installation]]

=== Verifying the Installation

After both scripts complete, verify that OpenShift AI components are running:

*Procedure*

[start=1]
. Check that the DataScienceCluster is Ready:

[source,sh,role=execute]
----
oc get datasciencecluster default-dsc -n redhat-ods-applications
----

[start=2]
. Verify the dashboard route exists:

[source,sh,role=execute]
----
oc get route rhods-dashboard -n redhat-ods-applications
----

[start=3]
. Check that the dashboard pod is running:

[source,sh,role=execute]
----
oc get pods -n redhat-ods-applications -l app=odh-dashboard
----

You should see a pod in "Running" status.

[[jupyter-notebooks-access]]

== Accessing Jupyter Notebooks

With OpenShift AI installed and the DataScienceCluster configured, data scientists can now access Jupyter notebooks through the OpenShift AI dashboard. The workbenches component provides a self-service environment where users can create and manage Jupyter notebook servers.

*Procedure*

[start=1]
. 